{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"UBNIY0sWqXMg","executionInfo":{"status":"ok","timestamp":1653148700542,"user_tz":-330,"elapsed":1100,"user":{"displayName":"","userId":""}}},"outputs":[],"source":["\n","import numpy as np\n","import h5py\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.gridspec as gridspec\n","import cv2\n","from keras.layers import Input,Dense,Reshape,Conv2D,Dropout,multiply,Dot,Concatenate,subtract,ZeroPadding2D\n","from keras.layers import BatchNormalization,LeakyReLU,Flatten\n","from keras.layers import Conv2DTranspose as Deconv2d\n","from keras.models import Model\n","\n","from tensorflow.keras.optimizers import Adam\n","\n","from google.colab import files\n","from keras import backend as K\n","import smtplib\n","\n","from sklearn.utils import shuffle\n","from google.colab import drive\n","\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"cRASEsOm1hPz","executionInfo":{"status":"ok","timestamp":1653148711273,"user_tz":-330,"elapsed":456,"user":{"displayName":"","userId":""}}},"outputs":[],"source":["def plot(A,B,C,n):\n","\n","    samples = [A,B,C]\n","    fig = plt.figure(figsize=(3,n))\n","    gs = gridspec.GridSpec(3,n)\n","    g=0\n","    for i in range(3):\n","        for j in range(n):\n","            ax = plt.subplot(gs[g])\n","            g+=1\n","            plt.axis('off')\n","            ax.set_xticklabels([])\n","            ax.set_yticklabels([])\n","            ax.set_aspect('equal')\n","            if samples[i][j].shape == (32,32,1):\n","              plt.imshow(samples[i][j].reshape(32, 32))\n","            else:\n","              plt.imshow(samples[i][j].reshape(32,32,3))\n","\n","    return fig"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"I1702nk3S3AI","executionInfo":{"status":"ok","timestamp":1653148716825,"user_tz":-330,"elapsed":642,"user":{"displayName":"","userId":""}}},"outputs":[],"source":["#for plotting any two images in case\n","\n","def ploty(A,B,n):\n","\n","    samples = [A,B]\n","    fig = plt.figure(figsize=(3,n))\n","    gs = gridspec.GridSpec(3,n)\n","    g=0\n","    for i in range(2):\n","        for j in range(n):\n","            ax = plt.subplot(gs[g])\n","            g+=1\n","            plt.axis('off')\n","            ax.set_xticklabels([])\n","            ax.set_yticklabels([])\n","            ax.set_aspect('equal')\n","            if samples[i][j].shape == (32,32,1):\n","              plt.imshow(samples[i][j].reshape(32, 32, 1))\n","            else:\n","              plt.imshow(samples[i][j].reshape(32,32,3))\n","\n","    return fig"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N68yNhL9z3jr","outputId":"9c062e78-8c7e-4bcb-9a21-4583e7fcb564","executionInfo":{"status":"ok","timestamp":1653148739740,"user_tz":-330,"elapsed":19857,"user":{"displayName":"","userId":""}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["drive.mount('/content/gdrive',force_remount=True)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"btWe5_6_y5tr","outputId":"23743bb2-0f81-49d7-85d3-614d9e901b0f","executionInfo":{"status":"ok","timestamp":1653148756196,"user_tz":-330,"elapsed":8639,"user":{"displayName":"","userId":""}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 2s 0us/step\n","170508288/170498071 [==============================] - 2s 0us/step\n","(50000, 32, 32, 1)\n","(50000, 32, 32, 3)\n"]}],"source":["from keras.datasets import cifar10\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","\n","y=x_train\n","x=np.sum(y, axis=3)/(3*255)\n","\n","y_test=x_test\n","x_test=np.sum(x_test, axis=3)/(3*255)   #for converting RGB into singe channel\n","x_test=x_test.reshape(10000, 32, 32, 1)\n","\n","\n","y=x_train/255\n","y=y*2-1\n","\n","\n","#x=x*2-1\n","#x=np.dot(y[...,:3], [0.299, 0.587, 0.114])/255\n","#x=x.reshape(50000,32, 32,1)\n","\n","x=x.reshape(50000, 32, 32, 1)\n","\n","print(x.shape)\n","print(y.shape)\n","  "]},{"cell_type":"code","execution_count":7,"metadata":{"id":"maALbVf-qmm0","executionInfo":{"status":"ok","timestamp":1653148761845,"user_tz":-330,"elapsed":392,"user":{"displayName":"","userId":""}}},"outputs":[],"source":["  \n","x_shape=(32,32,1)\n","y_shape=(32,32,3)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"cwbiitZCqo7r","executionInfo":{"status":"ok","timestamp":1653148764817,"user_tz":-330,"elapsed":394,"user":{"displayName":"","userId":""}}},"outputs":[],"source":["def Generator():\n","  X = Input(shape = x_shape)\n","  \n","  #C1 = ZeroPadding2D(padding=(1,1))(X)  \n","  C1 = Conv2D(64,kernel_size = 1, strides = 1,input_shape = x_shape)(X)\n","  C1 = LeakyReLU(0.2)(C1)\n","  \n","  C2 = Conv2D(128,kernel_size = 2, strides = 2)(C1)  \n","  C2 = LeakyReLU(0.2)(C2)\n","  \n","  C3 = Conv2D(256,kernel_size = 2, strides = 2)(C2)\n","  C3 = LeakyReLU(0.2)(C3)\n","  \n","  C4 = Conv2D(512,kernel_size = 2, strides = 2)(C3)\n","  C4 = LeakyReLU(0.2)(C4)\n","\n","  C5 = Conv2D(512, kernel_size = 2, strides = 2)(C4)\n","  C5 = LeakyReLU(0.2)(C5)\n","  \n","  \n","  DC0 = Deconv2d(512, kernel_size = 2, strides = 2)(C5)\n","  DC0 = LeakyReLU(0.2)(DC0)\n","  DC0 = BatchNormalization()(DC0)\n","  DC0 = Dropout(0.5)(DC0)\n","  DC0 = Concatenate(axis=3)([DC0, C4])\n","\n","  \n","  DC1 = Deconv2d(256,kernel_size=2, strides = 2)(DC0)\n","  DC1 = LeakyReLU(0.2)(DC1)\n","  DC1 = BatchNormalization()(DC1)  \n","  DC1 = Dropout(0.5)(DC1)             \n","  DC1 = Concatenate(axis=3)([DC1,C3])\n","\n","  \n","  DC2 = Deconv2d(128,kernel_size=2, strides = 2)(DC1)\n","  DC2 = LeakyReLU(0.2)(DC2)\n","  DC2 = BatchNormalization()(DC2)  \n","  DC2 = Concatenate(axis=3)([DC2,C2])\n","  \n","  DC3 = Deconv2d(64,kernel_size=2, strides = 2)(DC2)\n","  DC3 = LeakyReLU(0.2)(DC3)\n","  DC3 = BatchNormalization()(DC3)  \n","  DC3 = Concatenate(axis=3)([DC3,C1])\n","  \n","  #DC4 = ZeroPadding2D(padding=(3,1))(DC3)  \n","  CC4 = Conv2D(3,kernel_size=(1, 1), strides = (1, 1), activation=\"tanh\")(DC3)\n","  \n","  m = Model(X,CC4)\n","  #m.summary()\n","  return m\n","  "]},{"cell_type":"code","execution_count":9,"metadata":{"id":"g4X4dnGFqtKb","executionInfo":{"status":"ok","timestamp":1653148768950,"user_tz":-330,"elapsed":3,"user":{"displayName":"","userId":""}}},"outputs":[],"source":["def Discriminator():\n","  X = Input(shape = x_shape)\n","  Y = Input(shape = y_shape)\n","  \n","  In = Concatenate(axis=3)([X,Y])\n","  \n","  C1 = Conv2D(64,kernel_size = 2, strides = 2,input_shape = x_shape)(In)\n","  C1 = BatchNormalization()(C1)\n","  C1 = LeakyReLU(0.2)(C1)\n","  C2 = Conv2D(128,kernel_size = 2, strides = 2)(C1)  \n","  C2 = BatchNormalization()(C2)\n","  C2 = LeakyReLU(0.2)(C2)\n","  \n","  C3 = Conv2D(256,kernel_size = 2, strides = 2)(C2)\n","  C3 = BatchNormalization()(C3)\n","  C3 = LeakyReLU(0.2)(C3)\n","  \n","  C4 = Conv2D(512,kernel_size = 1, strides = 1)(C3)\n","  C4 = BatchNormalization()(C4)\n","  C4 = LeakyReLU(0.2)(C4)\n","  \n","  D = Flatten()(C4)\n","  D = Dense(128)(D)\n","  D = Dense(1,activation='sigmoid')(D)\n","  \n","  m = Model([X,Y],D)\n","  #m.summary()\n","  return m\n","   \n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"DSmYt36HqvHi","executionInfo":{"status":"ok","timestamp":1653148777151,"user_tz":-330,"elapsed":4163,"user":{"displayName":"","userId":""}}},"outputs":[],"source":["X = Input(shape = x_shape)\n","Y = Input(shape = y_shape)\n","\n","gen = Generator()\n","dis = Discriminator()\n","\n","out = gen(X)\n","comb = dis([X,out])\n","\n","out = Flatten()(out)\n","org = Flatten()(Y)\n","\n","cos_dis = Dot(axes = 1,normalize = True)([out,org])\n","\n","combined = Model([X,Y],[comb,cos_dis])"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"6aEF_YjzLI9l","executionInfo":{"status":"ok","timestamp":1653148781225,"user_tz":-330,"elapsed":404,"user":{"displayName":"","userId":""}}},"outputs":[],"source":["genLoss=[]\n","disLoss=[]"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C005zvKC1VGD","executionInfo":{"status":"ok","timestamp":1653148841468,"user_tz":-330,"elapsed":3,"user":{"displayName":"","userId":""}},"outputId":"bae5a987-95c3-4061-e168-45aea7f6b1c3"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]}],"source":["epochs = 3\n","batch_size = 50\n","n_example = 50000\n","batches = int(n_example/batch_size)\n","dis_updates = 2\n","gen_updates = 1\n","zero=np.zeros((batch_size,1))\n","one=np.ones((batch_size,1))*0.9\n","d_loss_factor = batches*2*dis_updates\n","g_loss_factor = batches*gen_updates\n","reuse = False\n","adams = Adam(lr = 0.0001)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"itR-uzoRVq_C","executionInfo":{"status":"ok","timestamp":1653148845084,"user_tz":-330,"elapsed":402,"user":{"displayName":"","userId":""}}},"outputs":[],"source":["#location in drive where models are present.\n","\n","if(reuse == True):\n","  gen.load_weights(\"gdrive/My Drive/newGAN/Generator.h5\")\n","  dis.load_weights(\"gdrive/My Drive/newGAN/Discriminator.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ffMSHzQq16E","outputId":"0abd2cda-61eb-4c27-d0f7-2780deace178"},"outputs":[{"output_type":"stream","name":"stdout","text":["##############\n","For Epoch:0\n","Training Discriminator\n"]}],"source":["\n","for epoch in range(epochs):\n","  print(\"##############\")\n","  print(\"For Epoch:\"+str(epoch))\n","  \n","  g_loss = 0\n","  d_loss = 0\n","  \n","  print(\"Training Discriminator\")\n","  \n","  i = shuffle(range(n_example))\n","  \n","  dis.trainable = True\n","  dis.compile(loss = \"binary_crossentropy\",optimizer = adams)\n","  \n","  for j in range(dis_updates):\n","      \n","    for b in range(batches):\n","        \n","      x_batch = x[i[b*batch_size:(b+1)*batch_size]]\n","      y_batch = y[i[b*batch_size:(b+1)*batch_size]]\n","      \n","      pre_batch = gen.predict(x_batch)\n","      \n","      d_loss += dis.train_on_batch([x_batch,y_batch],one)\n","      d_loss += dis.train_on_batch([x_batch,pre_batch],zero)\n","      \n","  print(\"Training Generator\")\n","  \n","  dis.trainable = False\n","  combined.compile(loss  = \"binary_crossentropy\", optimizer = adams)  \n","  dis.compile(loss = \"binary_crossentropy\",optimizer = adams)\n","        \n","  for  j in range(gen_updates):\n","    \n","    for b in range(batches):\n","      \n","      x_batch = x[i[b*batch_size:(b+1)*batch_size]]\n","      y_batch = y[i[b*batch_size:(b+1)*batch_size]]\n","      \n","        \n","      #in case the mode collapse takes place....commenting next two lines might help.\n","      #if b%4==3:\n","        #gl,_,_ = combined.train_on_batch([x_batch,y_batch],[zero,one])  \n","      \n","      gl,_,_ = combined.train_on_batch([x_batch,y_batch],[one,one])\n","      g_loss += gl\n","      \n","  g_loss /= g_loss_factor\n","  d_loss /= d_loss_factor\n","      \n","  print(\"Discriminator Loss:\"+str(d_loss))\n","  print(\"Generator loss:\"+str(g_loss))\n","  \n","  genLoss.append(g_loss)\n","  disLoss.append(d_loss)\n","  \n","  gen.save_weights(\"gdrive/My Drive/newGAN/Generator.h5\")\n","  dis.save_weights(\"gdrive/My Drive/newGAN/Discriminator.h5\")\n","  \n","\n","\n","  plt_indices = np.random.randint(50000,size=3)\n","  plt_a = x[plt_indices]\n","  plt_b = gen.predict(plt_a)\n","  plt_b = (plt_b+1)/2\n","  plt_c = (y[plt_indices]+1)/2\n","  fig = plot(plt_a,plt_b,plt_c,3)\n","  plt.show()\n","  plt.close(fig)\n"," \n","\n","\n","plt.plot(genLoss, c='r', label=\"Generator Loss\")\n","plt.plot(disLoss, c='b', label=\"Discriminator Loss\")\n","plt.xlabel(\"Iterations\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.show()\n","\n","files.download('gdrive/My Drive/GANModels/Generator.h5')\n","files.download('gdrive/My Drive/GANModels/Discriminator.h5')\n","\n","\n","\n","#for recieving mail on completion of training.\n","  # server = smtplib.SMTP('smtp.gmail.com', 587)\n","  # server.starttls()\n","  # server.login(\"************@gmail.com\", \"*********\")\n","  \n","  # msg = \"COLAB WORK FINISH ALERT!\"\n","  # server.sendmail(\"snaik4398@gmail.com\", \"********@nirmauni.ac.in\", msg)\n","  # server.quit()\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Copy of GANForProject.ipynb","provenance":[{"file_id":"https://github.com/PartheshSoni/Image-colorization-using-GANs/blob/master/ImageColourization.ipynb","timestamp":1653148994559}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":0}